{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/Larinwa/5e79f7dd1659d0bdaf4cbf6080777819/getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sg7gTYi7WEA"
      },
      "source": [
        "# WEB SCRAPING \n",
        " We will use a package called `BeautifulSoup` to collect the data from the web and save it into a local `.csv` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfT6pVGk7WEC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Pf8Hlt07WEC",
        "outputId": "3f828d95-987f-45d4-cdd1-aa33da92fd38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping page 1\n",
            "   ---> 100 total reviews\n",
            "Scraping page 2\n",
            "   ---> 200 total reviews\n",
            "Scraping page 3\n",
            "   ---> 300 total reviews\n",
            "Scraping page 4\n",
            "   ---> 400 total reviews\n",
            "Scraping page 5\n",
            "   ---> 500 total reviews\n",
            "Scraping page 6\n",
            "   ---> 600 total reviews\n",
            "Scraping page 7\n",
            "   ---> 700 total reviews\n",
            "Scraping page 8\n",
            "   ---> 800 total reviews\n",
            "Scraping page 9\n",
            "   ---> 900 total reviews\n",
            "Scraping page 10\n",
            "   ---> 1000 total reviews\n"
          ]
        }
      ],
      "source": [
        "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
        "pages = 10\n",
        "page_size = 100\n",
        "\n",
        "reviews = []\n",
        "\n",
        "# for i in range(1, pages + 1):\n",
        "for i in range(1, pages + 1):\n",
        "\n",
        "    print(f\"Scraping page {i}\")\n",
        "\n",
        "    # Create URL to collect links from paginated data\n",
        "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
        "\n",
        "    # Collect HTML data from this page\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse content\n",
        "    content = response.content\n",
        "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
        "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
        "        reviews.append(para.get_text())\n",
        "\n",
        "    print(f\"   ---> {len(reviews)} total reviews\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3wwGJlN7WED",
        "outputId": "e3714ac7-e3bb-4dcd-ea82-33ecb1766a05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>✅ Trip Verified |   Appalling service with fai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>✅ Trip Verified | British Airways charge you f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>✅ Trip Verified | What is wrong with you guys?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>✅ Trip Verified |   We booked two business cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>✅ Trip Verified | I’ve flown with many airline...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews\n",
              "0  ✅ Trip Verified |   Appalling service with fai...\n",
              "1  ✅ Trip Verified | British Airways charge you f...\n",
              "2  ✅ Trip Verified | What is wrong with you guys?...\n",
              "3  ✅ Trip Verified |   We booked two business cla...\n",
              "4  ✅ Trip Verified | I’ve flown with many airline..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"reviews\"] = reviews\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VckgEGD67WED",
        "outputId": "bc1f57df-8bd1-477a-ee9a-d5413a242a95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQcM6ui77WED",
        "outputId": "16e66842-49a2-4b8b-c4ba-695b767c6299"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>✅ Trip Verified |   Appalling service with fai...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>✅ Trip Verified | British Airways charge you f...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>✅ Trip Verified | What is wrong with you guys?...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>✅ Trip Verified |   We booked two business cla...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>✅ Trip Verified | I’ve flown with many airline...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews Sentiment\n",
              "0  ✅ Trip Verified |   Appalling service with fai...  Negative\n",
              "1  ✅ Trip Verified | British Airways charge you f...  Positive\n",
              "2  ✅ Trip Verified | What is wrong with you guys?...  Negative\n",
              "3  ✅ Trip Verified |   We booked two business cla...  Negative\n",
              "4  ✅ Trip Verified | I’ve flown with many airline...  Positive"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "# Initialize the sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define a function to analyze sentiment\n",
        "def analyze_sentiment(text):\n",
        "    sentiment = sia.polarity_scores(text)\n",
        "    if sentiment['compound'] >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif sentiment['compound'] <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply the sentiment analysis function to the text column\n",
        "df['Sentiment'] = df['reviews'].apply(analyze_sentiment)\n",
        "\n",
        "# Print the updated DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYa_10i67WED",
        "outputId": "84e34c48-d02b-48bb-bccf-32f0181bb771"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Negative    515\n",
              "Positive    471\n",
              "Neutral      14\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent= df['Sentiment']\n",
        "sent.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSlPEWLM7WEE"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"data/BA_reviews.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4WPOgLp7WEE"
      },
      "source": [
        "Now we have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if we want to collect more data, all we need to do is to increase the number of pages."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}